{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from cbastats.DBHelper import MongoDBHelper\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from utils.datarefresher import get_current_season, set_logging_config\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOTENV_PATH=\".\"\n",
    "env_path = Path(DOTENV_PATH) / '.env'\n",
    "if not (env_path.exists()):\n",
    "    print('.env file is missing.')\n",
    "    sys.exit()\n",
    "load_dotenv(dotenv_path=env_path,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_envs = ['MONGODB_PWD', 'MONGODB_USERNAME', 'MONGODB_ENDPOINT','LOGGER_NAME']\n",
    "envs = os.environ\n",
    "# only checks if user wants to save data to DB\n",
    "# check if all needed environment variables are present\n",
    "\n",
    "for needed_env in needed_envs:\n",
    "    if needed_env not in envs:\n",
    "        raise Exception(f\"Missing environment variable: {needed_env}.\\n     Please check if these environment variables are present: {needed_envs}\")\n",
    "    config[needed_env] = envs[needed_env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing database ['cbaStats', 'nbaStats', 'admin', 'local']\n"
     ]
    }
   ],
   "source": [
    "mongodbio = MongoDBHelper()\n",
    "client = mongodbio.create_connection(\n",
    "    config['MONGODB_USERNAME'], config['MONGODB_PWD'], config['MONGODB_ENDPOINT'])\n",
    "nba_db = client['nbaStats']\n",
    "# coll_nbaGames = nba_db['nbaGames']\n",
    "# coll_nbaGamesStaging= nba_db['nbaGamesStaging']\n",
    "# coll_nbaBoxScores = nba_db['nbaProcessedBoxScores']\n",
    "\n",
    "# in the future, when you have multiple features table, iterate through the tables\n",
    "# or better yet, built a feature store\n",
    "coll_feat = nba_db['nbaTeamFeat_Past10Games_Avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = set_logging_config(config['LOGGER_NAME'],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['random_state'] = 248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team based - simple average of past xx games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training/Validation/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from dtreeviz.trees import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'VISITOR', 'DATEWeek', 'VISITOR_PTS', 'HOME', 'HOME_PTS',\n",
       "       'boxscores_url', 'game_id', 'Pace_home', 'eFG%_home', 'TOV%_home',\n",
       "       'TS%_home', '3PAr_home', 'FTr_home', 'DRB%_home', 'TRB%_home',\n",
       "       'AST%_home', 'STL%_home', 'BLK%_home', 'DRtg_home', 'ORB%_home',\n",
       "       'FT/FGA_home', 'ORtg_home', 'Pace_visitor', 'eFG%_visitor',\n",
       "       'TOV%_visitor', 'ORB%_visitor', 'FT/FGA_visitor', 'ORtg_visitor',\n",
       "       'TS%_visitor', '3PAr_visitor', 'FTr_visitor', 'DRB%_visitor',\n",
       "       'TRB%_visitor', 'AST%_visitor', 'STL%_visitor', 'BLK%_visitor',\n",
       "       'DRtg_visitor', 'TOTAL_PTS', 'HOME_VISITOR_PTS_DIFF', 'HOME_WIN',\n",
       "       'DATEYear', 'DATEMonth', 'DATEDay', 'DATEDayofweek', 'DATEDayofyear',\n",
       "       'DATEIs_month_end', 'DATEIs_month_start', 'DATEIs_quarter_end',\n",
       "       'DATEIs_quarter_start', 'DATEIs_year_end', 'DATEIs_year_start',\n",
       "       'DATEElapsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the processed data\n",
    "teamstats = pd.DataFrame(mongodbio.select_records(coll_feat,\n",
    "                                                  filter={\"season\":{\"$in\":['2020-2021','2019-2020','2018-2019',\n",
    "                                                                          '2017-2018','2016-2017','2015-2016']}},\n",
    "                                                  field={'_id':0}))\n",
    "teamstats = add_datepart(teamstats, 'DATE')\n",
    "teamstats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 53)\n"
     ]
    }
   ],
   "source": [
    "print(teamstats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set what are dependent variables, what are independent variables\n",
    "config['dep_variable'] = ['HOME_WIN']\n",
    "config['ind_variable'] = ([col for col in teamstats.columns if col.endswith(\"_home\")] + \n",
    "                         [col for col in teamstats.columns if col.endswith(\"_visitor\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3457, 865, 481]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test set\n",
    "other_idx,test_idx = train_test_split(list(teamstats.index),test_size=0.1,random_state=config['random_state'])\n",
    "test_set = teamstats.loc[test_idx,config['ind_variable']+config['dep_variable']].copy()\n",
    "\n",
    "# get train set and valid set\n",
    "# don't want to mix non-test set with training set, therefore \"other_set\"\n",
    "other_set = teamstats.loc[other_idx,config['ind_variable']+config['dep_variable']].copy()\n",
    "train_idx,valid_idx = train_test_split(list(other_set.reset_index(drop=True).index),test_size=0.2,random_state=config['random_state'])\n",
    "[len(idx) for idx in [train_idx,valid_idx,test_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pace_home', 'eFG%_home', 'TOV%_home', 'TS%_home', '3PAr_home', 'FTr_home', 'DRB%_home', 'TRB%_home', 'AST%_home', 'STL%_home', 'BLK%_home', 'DRtg_home', 'ORB%_home', 'FT/FGA_home', 'ORtg_home', 'Pace_visitor', 'eFG%_visitor', 'TOV%_visitor', 'ORB%_visitor', 'FT/FGA_visitor', 'ORtg_visitor', 'TS%_visitor', '3PAr_visitor', 'FTr_visitor', 'DRB%_visitor', 'TRB%_visitor', 'AST%_visitor', 'STL%_visitor', 'BLK%_visitor', 'DRtg_visitor'] []\n"
     ]
    }
   ],
   "source": [
    "# split continuous variables and categorical variabls\n",
    "cont_var, cat_var=cont_cat_split(other_set,dep_var=config['dep_variable'])\n",
    "print(cont_var,cat_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3457, 865)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a tabular object\n",
    "to=TabularPandas(other_set,cat_names=cat_var,cont_names=cont_var,\n",
    "                 y_names=config['dep_variable'],splits=(train_idx,valid_idx))\n",
    "len(to.train),len(to.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3457\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "xs,y = to.train.xs,to.train.y\n",
    "valid_xs,valid_y = to.valid.xs,to.valid.y\n",
    "print(len(xs))\n",
    "print(len(valid_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Neptune to Record Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(jjnotjimmyjohn/NBA-Score-Prediction)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.init(project_qualified_name='jjnotjimmyjohn/NBA-Score-Prediction')\n",
    "# neptune.init(project_qualified_name='jjnotjimmyjohn/sandbox',api_token=neptune.ANONYMOUS_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment name should not show other things except your training objective\n",
    "# winclassification\n",
    "\n",
    "# objective\n",
    "# model params\n",
    "# features\n",
    "# accuracy\n",
    "\n",
    "# TODO: instead of using pandas built-ins to calculate features, use custom functions. \n",
    "# that way you can use function as parameters, easier to log and streamline\n",
    "def record_experiment(model,feat_name,model_objective,\n",
    "                      x,y,valid_x,valid_y,metric_name,metric_func,\n",
    "                      tags:list,\n",
    "                      proj_name='jjnotjimmyjohn/NBA-Score-Prediction'):\n",
    "    # create experiment\n",
    "    neptune.set_project(proj_name)\n",
    "    neptune.create_experiment(name=model_objective)\n",
    "    if hasattr(model,'best_estimator_'):\n",
    "        param_log = model.best_estimator_.get_params()\n",
    "    else:\n",
    "        param_log = model.get_params()\n",
    "    neptune.log_text('best_model', str(param_log))\n",
    "    try:\n",
    "        neptune.log_text('model_type',type(model).__name__)\n",
    "    except:\n",
    "        print('No model name is recorded')\n",
    "        neptune.log_text('model_type',\"unknown\")\n",
    "    neptune.log_metric('training_'+metric_name, metric_func(y,model.predict(xs)))\n",
    "    neptune.log_metric('validation_'+metric_name, metric_func(valid_y,model.predict(valid_xs)))\n",
    "    if tags:\n",
    "        for tag in tags:\n",
    "            neptune.append_tags(*tags)\n",
    "    # for key,value in args.items():\n",
    "    #     neptune.set_property(key,value)\n",
    "    neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import SCORERS,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters distribution to randomized search\n",
    "dt_params_dist={\n",
    "    'min_samples_split':[5,10,15,20],\n",
    "    'min_samples_leaf':[10,20,30,40,60],\n",
    "    'max_features':[0.5,0.6,0.7,0.8,0.9],\n",
    "}\n",
    "# base model\n",
    "base_model = DecisionTreeClassifier(random_state=config['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbaTeamFeat_PastNGames_Avg\n"
     ]
    }
   ],
   "source": [
    "print(coll_feat.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 90 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=6)]: Done 720 out of 720 | elapsed:   19.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=8, estimator=DecisionTreeClassifier(random_state=248),\n",
       "                   n_iter=90, n_jobs=6,\n",
       "                   param_distributions={'max_features': [0.5, 0.6, 0.7, 0.8,\n",
       "                                                         0.9],\n",
       "                                        'min_samples_leaf': [10, 20, 30, 40,\n",
       "                                                             60],\n",
       "                                        'min_samples_split': [5, 10, 15, 20]},\n",
       "                   return_train_score=True, verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(base_model,dt_params_dist,n_iter=90,n_jobs=6,\n",
    "                                   cv=8,verbose=5,return_train_score=True,refit=True)\n",
    "model.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7038518206693327\n",
      "0.5808080808080808\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y,model.predict(xs)))\n",
    "print(accuracy_score(valid_y,model.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "# neptune.set_project('jjnotjimmyjohn/NBA-Score-Prediction')\n",
    "# neptune.create_experiment(name='TeamBasedModel_moredata',description='',params=model.get_params())\n",
    "# neptune.append_tag(f'summarize_past_games')\n",
    "# neptune.append_tag(f'decision_tree')\n",
    "# neptune.append_tag(f'randomized_search_cv')\n",
    "# neptune.log_metric('training_error', mean_absolute_error(y,model.predict(xs)))\n",
    "# neptune.log_metric('validation_error', mean_absolute_error(valid_y,model.predict(valid_xs)))\n",
    "# neptune.log_text('best_model', str(model.best_estimator_))\n",
    "# for key,value in args.items():\n",
    "#     neptune.set_property(key,value)\n",
    "# neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randome Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters distribution to randomized search\n",
    "dt_params_dist={\n",
    "    'min_samples_split':[5,10,15,20],\n",
    "    'max_samples':[0.5,0.7,0.8,0.9,1],\n",
    "    'min_samples_leaf':[30,40,50],\n",
    "    'max_features':[0.6,0.7,0.8,0.9,1],\n",
    "}\n",
    "# base model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RandomForestRegressor(n_jobs=-1, n_estimators=1000,\n",
    "    max_samples=len(xs), max_features=0.7,\n",
    "    min_samples_leaf=25, oob_score=True).fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719409892970784\n",
      "0.6323699421965318\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1, n_estimators=2000, oob_score=True, min_samples_leaf=45)\n",
    "base_model.fit(xs,y)\n",
    "print(accuracy_score(y,base_model.predict(xs)))\n",
    "print(accuracy_score(valid_y,base_model.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 100 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed: 54.4min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed: 120.1min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed: 152.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=8,\n",
       "                   estimator=RandomForestClassifier(min_samples_leaf=45,\n",
       "                                                    n_estimators=2000,\n",
       "                                                    n_jobs=-1, oob_score=True),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_features': [0.6, 0.7, 0.8, 0.9, 1],\n",
       "                                        'max_samples': [0.5, 0.7, 0.8, 0.9, 1],\n",
       "                                        'min_samples_leaf': [30, 40, 50],\n",
       "                                        'min_samples_split': [5, 10, 15, 20]},\n",
       "                   return_train_score=True, verbose=5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(base_model,dt_params_dist,n_iter=100,n_jobs=-1,\n",
    "                                   cv=8,verbose=5,return_train_score=True,refit=True)\n",
    "model.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7331088191959587\n",
      "0.6338383838383839\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y,model.predict(xs)))\n",
    "print(accuracy_score(valid_y,model.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jjnotjimmyjohn/NBA-Score-Prediction/e/NBAS-6\n"
     ]
    }
   ],
   "source": [
    "record_experiment(model=model,feat_name=coll_feat.name,model_objective=\"winloss_classification\",\n",
    "                  x=xs,y=y,valid_x=valid_xs,valid_y=valid_y,metric_name='Accuracy',metric_func=accuracy_score,\n",
    "                 proj_name='jjnotjimmyjohn/NBA-Score-Prediction')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(mean_absolute_error(y,m.predict(xs))) # 9.055876795592912\n",
    "print(mean_absolute_error(valid_y,m.predict(valid_xs))) # 10.29984097314067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01541239, 0.01973962, 0.02409648, 0.03867845, 0.02027797,\n",
       "       0.01485195, 0.01925435, 0.02022374, 0.02326313, 0.02133321,\n",
       "       0.02107099, 0.11722661, 0.01321176, 0.01650976, 0.15388962,\n",
       "       0.02079595, 0.04096719, 0.01557033, 0.01808111, 0.01483974,\n",
       "       0.07810076, 0.05194351, 0.02509932, 0.01461921, 0.02030002,\n",
       "       0.02028742, 0.02362852, 0.01930176, 0.02542785, 0.07199728])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORtg_home</td>\n",
       "      <td>0.153890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DRtg_home</td>\n",
       "      <td>0.117227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORtg_visitor</td>\n",
       "      <td>0.078101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DRtg_visitor</td>\n",
       "      <td>0.071997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TS%_visitor</td>\n",
       "      <td>0.051944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eFG%_visitor</td>\n",
       "      <td>0.040967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TS%_home</td>\n",
       "      <td>0.038678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BLK%_visitor</td>\n",
       "      <td>0.025428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3PAr_visitor</td>\n",
       "      <td>0.025099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOV%_home</td>\n",
       "      <td>0.024096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AST%_visitor</td>\n",
       "      <td>0.023629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AST%_home</td>\n",
       "      <td>0.023263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STL%_home</td>\n",
       "      <td>0.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BLK%_home</td>\n",
       "      <td>0.021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pace_visitor</td>\n",
       "      <td>0.020796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DRB%_visitor</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TRB%_visitor</td>\n",
       "      <td>0.020287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3PAr_home</td>\n",
       "      <td>0.020278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRB%_home</td>\n",
       "      <td>0.020224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eFG%_home</td>\n",
       "      <td>0.019740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>STL%_visitor</td>\n",
       "      <td>0.019302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DRB%_home</td>\n",
       "      <td>0.019254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORB%_visitor</td>\n",
       "      <td>0.018081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FT/FGA_home</td>\n",
       "      <td>0.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOV%_visitor</td>\n",
       "      <td>0.015570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pace_home</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FTr_home</td>\n",
       "      <td>0.014852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FT/FGA_visitor</td>\n",
       "      <td>0.014840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FTr_visitor</td>\n",
       "      <td>0.014619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORB%_home</td>\n",
       "      <td>0.013212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cols       imp\n",
       "14       ORtg_home  0.153890\n",
       "11       DRtg_home  0.117227\n",
       "20    ORtg_visitor  0.078101\n",
       "29    DRtg_visitor  0.071997\n",
       "21     TS%_visitor  0.051944\n",
       "16    eFG%_visitor  0.040967\n",
       "3         TS%_home  0.038678\n",
       "28    BLK%_visitor  0.025428\n",
       "22    3PAr_visitor  0.025099\n",
       "2        TOV%_home  0.024096\n",
       "26    AST%_visitor  0.023629\n",
       "8        AST%_home  0.023263\n",
       "9        STL%_home  0.021333\n",
       "10       BLK%_home  0.021071\n",
       "15    Pace_visitor  0.020796\n",
       "24    DRB%_visitor  0.020300\n",
       "25    TRB%_visitor  0.020287\n",
       "4        3PAr_home  0.020278\n",
       "7        TRB%_home  0.020224\n",
       "1        eFG%_home  0.019740\n",
       "27    STL%_visitor  0.019302\n",
       "6        DRB%_home  0.019254\n",
       "18    ORB%_visitor  0.018081\n",
       "13     FT/FGA_home  0.016510\n",
       "17    TOV%_visitor  0.015570\n",
       "0        Pace_home  0.015412\n",
       "5         FTr_home  0.014852\n",
       "19  FT/FGA_visitor  0.014840\n",
       "23     FTr_visitor  0.014619\n",
       "12       ORB%_home  0.013212"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = rf_feat_importance(model.best_estimator_, xs)\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7162279433034423\n",
      "0.6497109826589595\n"
     ]
    }
   ],
   "source": [
    "base_model = xg.XGBClassifier(n_estimators = 6, seed = config['random_state'],max_depth=4,reg_lambda=0.1, \n",
    "                             learning_rate=0.4)\n",
    "base_model.fit(xs,y)\n",
    "print(accuracy_score(y,base_model.predict(xs)))\n",
    "print(accuracy_score(valid_y,base_model.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xg_params_dist={\n",
    "    \"n_estimators\":list(range(5,16)),\n",
    "    \"max_depth\":[3,4,5,6],\n",
    "    \"reg_lambda\":[0.1,0.2,0.3],\n",
    "    \"learning_rate\":[0.05,0.07,0.1,0.2,0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params_dist={\n",
    "    \"n_estimators\":[6],\n",
    "    \"max_depth\":[4],\n",
    "    \"reg_lambda\":[0.1],\n",
    "    \"learning_rate\":[0.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 1 is smaller than n_iter=500. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.6s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.8s finished\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=8,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate='0.4',\n",
       "                                           max_delta_step=0, max_depth=4,\n",
       "                                           min_child_weight=1, missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=6, n_jobs=6,\n",
       "                                           num_parallel_tree=1,\n",
       "                                           random_state=248, reg_alpha=0,\n",
       "                                           reg_lambda=0.1, scale_pos_weight=1,\n",
       "                                           seed=248, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=500, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.4],\n",
       "                                        'max_depth': [4], 'n_estimators': [6],\n",
       "                                        'reg_lambda': [0.1]},\n",
       "                   return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(base_model,xg_params_dist,n_iter=500,n_jobs=-1,\n",
    "                                   cv=8,verbose=3,return_train_score=True,refit=True)\n",
    "model.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7162279433034423\n",
      "0.6497109826589595\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y,base_model.predict(xs)))\n",
    "print(accuracy_score(valid_y,base_model.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jjnotjimmyjohn/NBA-Score-Prediction/e/NBAS-16\n"
     ]
    }
   ],
   "source": [
    "record_experiment(model=model,feat_name=coll_feat.name,model_objective=\"winloss_classification\",\n",
    "                  x=xs,y=y,valid_x=valid_xs,valid_y=valid_y,metric_name='Accuracy',metric_func=accuracy_score,\n",
    "                  tags=['use recent 6 seasons'],\n",
    "                  proj_name='jjnotjimmyjohn/NBA-Score-Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6528782181081862\n",
      "0.6358381502890174\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=0.5,kernel='linear')\n",
    "\n",
    "svc.fit(xs,y)\n",
    "\n",
    "print(accuracy_score(y,svc.predict(xs)))\n",
    "print(accuracy_score(valid_y,svc.predict(valid_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jjnotjimmyjohn/NBA-Score-Prediction/e/NBAS-19\n"
     ]
    }
   ],
   "source": [
    "record_experiment(model=svc,feat_name=coll_feat.name,model_objective=\"winloss_classification\",\n",
    "                  x=xs,y=y,valid_x=valid_xs,valid_y=valid_y,metric_name='Accuracy',metric_func=accuracy_score,\n",
    "                  tags=['use recent 6 seasons'],\n",
    "                  proj_name='jjnotjimmyjohn/NBA-Score-Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sequential'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmaxscaler = MinMaxScaler()\n",
    "minmaxscaler.fit(xs)\n",
    "xs_norm = minmaxscaler.transform(xs)\n",
    "valid_xs_norm = minmaxscaler.transform(valid_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covnert to Tensors\n",
    "tensor_xs_norm = torch.Tensor(xs_norm) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(y.values).unsqueeze(1)\n",
    "tensor_valid_xs_norm = torch.Tensor(valid_xs_norm) # transform to torch tensor\n",
    "tensor_valid_y = torch.Tensor(valid_y.values).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Dataset\n",
    "xs_ds=torch.utils.data.TensorDataset(tensor_xs_norm,tensor_y)\n",
    "valid_xs_ds=torch.utils.data.TensorDataset(tensor_valid_xs_norm,tensor_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(xs_ds,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.20004931092262268\n",
      "epoch 1, loss 0.2347828447818756\n",
      "epoch 2, loss 0.2199774831533432\n",
      "epoch 3, loss 0.144601970911026\n",
      "epoch 4, loss 0.6668237447738647\n",
      "epoch 5, loss 0.16621433198451996\n",
      "epoch 6, loss 0.0429544635117054\n",
      "epoch 7, loss 0.0805291160941124\n",
      "epoch 8, loss 0.3907792568206787\n",
      "epoch 9, loss 0.07786593586206436\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(tensor_xs_norm.shape[1],2048),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(2048,1024),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1024,512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512,256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(32,1),\n",
    "                      nn.Sigmoid()\n",
    "                     )\n",
    "\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for data in data_loader:\n",
    "\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(data[0])\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs, data[1])\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5446)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((model(tensor_valid_xs_norm)>0.5).squeeze()==tensor_valid_y)*1.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Model - team based - similar opponents as training data\n",
    "获取球队最近几场与相似对手交手时，取得的数据作为training data\n",
    "\n",
    "相似对手：\n",
    "\n",
    "1. 将ortg和drtg作为x轴y轴，几何距离最近的对手\n",
    "\n",
    "1. 用什么的ortg，drtg？所有本赛季已进行的比赛的数据？单场？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model - Player based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players? -> include minutes played\n",
    "# injured players?\n",
    "# use news to guess how many minutes he will play"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
